{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [REQUIRED]\n",
    "\n",
    "* `pip install torch torchaudio torchvision torchtext`\n",
    "* install `tensorboard` and `jupyter` from VSCode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch basics\n",
    "\n",
    "reference \n",
    "* https://pytorch.org/docs/stable/torch.html\n",
    "* https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch as tt\n",
    "#import torchvision, torchaudio, torchtext\n",
    "print(f'{tt.__version__=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc = tt.nn.JANETCell(input_size=3, hidden_size=6, bias=False)\n",
    "jc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tensor(data=None, dtype=None, device=None, requires_grad=None)       # always creates a copy, (use .clone().detach())\n",
    "tt.as_tensor(data=None, dtype=None, device=None, requires_grad=None)    # preserves autograd history and avoids copies where possible.\n",
    "tt.from_numpy(data=None, dtype=None, device=None, requires_grad=None)   # creates a tensor that shares storage with a NumPy array.\n",
    "\n",
    "tt.zeros(size=None, dtype=None, device=None, requires_grad=None)\n",
    "tt.zeros_like(input=None, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.ones(size=None, dtype=None, device=None, requires_grad=None)\n",
    "tt.ones_like(input=None, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.empty(size=None, dtype=None, device=None, requires_grad=None)\n",
    "tt.empty_like(input=None, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.full(size=None, fill_value=None, dtype=None, device=None, requires_grad=None)\n",
    "tt.full_like(input=None, fill_value=None, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.arange(start=None, end=None, step=None, dtype=None, device=None, requires_grad=None) # returs 1-D tensors\n",
    "tt.linspace(start=None, end=None, steps=None, dtype=None, device=None, requires_grad=None) # returs 1-D tensors\n",
    "tt.logspace(start=None, end=None, steps=None, base=None, dtype=None, device=None, requires_grad=None) # returs 1-D tensors\n",
    "\n",
    "tt.eye(n=None, m=None, dtype=None, device=None, requires_grad=None) # (n,m) identity matrix (2-D), optinal m=n\n",
    "tt.heaviside(input=None, values=None, dtype=None, device=None, requires_grad=None) # shapes like input, (0,1,v) if input(<0,>0,==0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNG Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = tt.Generator() # https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator\n",
    "rng # rng can be passed to other random generating functions of torch (like in place sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.initial_seed() # shows the current seed for rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.manual_seed(rng.initial_seed()+1)  # set the seed to rng to something manually\n",
    "#  It is recommended to set a large seed, i.e. a number that has a good balance of 0 and 1 bits. Avoid having many 0 bits in the seed.\n",
    "rng.initial_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.seed() # set the seed to rng to something randomly\n",
    "# Gets a non-deterministic random number from std::random_device or the current time and uses it to seed a Generator.\n",
    "rng.initial_seed()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting RNG states"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1] - store the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_state = rng.get_state()\n",
    "# Returns the Generator state as a torch.ByteTensor.\n",
    "# A torch.ByteTensor which contains all the necessary bits to restore a Generator to a specific point in time.\n",
    "rng.initial_seed(), rng_state #<---- current rng state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2] - set random seed - changes the current state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.seed() #<--- we change the rng state by seeding randomly\n",
    "rng.initial_seed(), rng.get_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] - restore the orignal state from (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.set_state(rng_state) #<---- reverting back to orignal state before random seeding\n",
    "rng.initial_seed(), rng.get_state()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by default, the rng used by torch can be manipulated using same functions as described in the RNG Generator section above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initial-Seed:', tt.initial_seed()) # current seed for default rng\n",
    "\n",
    "# set seed\n",
    "tt.manual_seed(tt.initial_seed()+1) # manually sets a seed for random sampling creation ops\n",
    "print('Manual-Seed:', tt.initial_seed()) # current seed for default rng\n",
    "\n",
    "# or \n",
    "tt.seed() # randomly sets a seed for random sampling creation ops\n",
    "print('Random-Seed:', tt.initial_seed()) # current seed for default rng\n",
    "\n",
    "# we can use 'get_rng_state()' and 'set_rng_state()' similarily"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation Ops - Random Sampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cannot use `requires_grad` for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.bernoulli(\n",
    "    input=tt.tensor([0.5, 0.5]),  # a tensor containing probability value of generating a 1\n",
    "    generator=rng)\n",
    "    \n",
    "tt.multinomial(\n",
    "    input=tt.tensor([[2.0, 4.0, 3.0], [4.0, 7.0, 5.0]]), # probability or weights\n",
    "    # The rows of input do not need to sum to one (in which case we use the values as weights), \n",
    "    # but must be non-negative, finite and have a non-zero sum.\n",
    "    # If input is a vector, out is a vector of size num_samples.\n",
    "    # If input is a matrix with m rows, out is an matrix of shape (m, num_samples).\n",
    "    num_samples=4,\n",
    "    replacement=True,\n",
    "    generator=rng)\n",
    "\n",
    "tt.normal(\n",
    "    mean=tt.tensor([[2.0, 4.0, 3.0], [4.0, 7.0, 5.0]]),\n",
    "    std=tt.tensor([[2.0, 4.0, 3.0], [4.0, 7.0, 5.0]]),\n",
    "    generator=rng)\n",
    "\n",
    "tt.poisson(\n",
    "    input=tt.tensor([[2.0, 4.0, 3.0], [4.0, 7.0, 5.0]]), # contains 'rate' for possion distribution\n",
    "    generator=rng)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can use `requires_grad` for these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.rand(size=(1,2), dtype=None, device=None, requires_grad=None)\n",
    "tt.rand_like(input=None, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.randint(low=0, high=10, size=(3,4), dtype=None, device=None, requires_grad=None)\n",
    "tt.randint_like(input=None, low=0, high=10, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.randn(size=(1,2), dtype=None, device=None, requires_grad=None)\n",
    "tt.randn_like(input=None, dtype=None, device=None, requires_grad=None)\n",
    "\n",
    "tt.randperm(n=10, dtype=None, device=None, requires_grad=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inplace Ops - Random Sampling\n",
    "\n",
    "https://pytorch.org/docs/stable/torch.html#in-place-random-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.Tensor.bernoulli_() #- in-place version of torch.bernoulli()\n",
    "\n",
    "tt.Tensor.cauchy_() #- numbers drawn from the Cauchy distribution\n",
    "\n",
    "tt.Tensor.exponential_() #- numbers drawn from the exponential distribution\n",
    "\n",
    "tt.Tensor.geometric_() #- elements drawn from the geometric distribution\n",
    "\n",
    "tt.Tensor.log_normal_() #- samples from the log-normal distribution\n",
    "\n",
    "tt.Tensor.normal_() #- in-place version of torch.normal()\n",
    "\n",
    "tt.Tensor.random_() #- numbers sampled from the discrete uniform distribution\n",
    "\n",
    "tt.Tensor.uniform_() #- numbers sampled from the continuous uniform distribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing, Slicing, Joining, Mutating Ops\n",
    "\n",
    "https://pytorch.org/docs/stable/torch.html#in-place-random-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic slicing\n",
    "tt.Tensor[ 'start':'stop':'step', ..., ..., ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.cat(tensors='List or tuple of tensors', dim='dimension') # same as concat, cancatenate\n",
    "# torch.cat() can be seen as an inverse operation for torch.split() and torch.chunk().\n",
    "\n",
    "tt.chunk(input='tensor', chunks='int', dim=0) # -> List of Tensors - chunks are views\n",
    "# This function may return less then the specified number of chunks!\n",
    "# If the tensor size along the given dimesion dim is divisible by chunks, all returned chunks will be the same size. \n",
    "# If the tensor size along the given dimension dim is not divisible by chunks, all returned chunks will be the same size, except the last one. \n",
    "# If such division is not possible, this function may return less than the specified number of chunks.\n",
    "\n",
    "tt.split(tensor='tensor', split_size_or_sections='int of list_of_int', dim=0) # Splits the tensor into chunks. \n",
    "# Each chunk is a view of the original tensor.\n",
    "# If split_size_or_sections is an integer type, then tensor will be split into equally sized chunks (if possible). \n",
    "# Last chunk will be smaller if the tensor size along the given dimension dim is not divisible by split_size.\n",
    "# If split_size_or_sections is a list, then tensor will be split into len(split_size_or_sections) chunks \n",
    "# with sizes in dim according to split_size_or_sections\n",
    "\n",
    "tt.tensor_split(input='tensor', indices_or_sections=\"Tensor, int or list or tuple of ints\", dim=0) # -> List of Tensors, as views\n",
    "# If indices_or_sections is an integer n or a zero dimensional long tensor with value n, input is split into n sections along dimension dim. \n",
    "# If input is divisible by n along dimension dim, each section will be of equal size, input.size(dim) / n. \n",
    "# If input is not divisible by n, the sizes of the first int(input.size(dim) % n) sections will have size int(input.size(dim) / n) + 1, \n",
    "# and the rest will have size int(input.size(dim) / n).\n",
    "# If indices_or_sections is a list or tuple of ints, or a one-dimensional long tensor, \n",
    "# then input is split along dimension dim at each of the indices in the list, tuple or tensor\n",
    "tt.hsplit(), tt.vsplit(), tt.dsplit() # are some similar functions\n",
    "\n",
    "\n",
    "\n",
    "tt.stack(tensors='List or tuple of tensors', dim=0) # ->Tensor\n",
    "# Concatenates a sequence of tensors along a new dimension. All tensors need to be of the same size.\n",
    "tt.hstack(), tt.vstack(), tt.dstack() # are some similar functions\n",
    "tt.row_stack() # alias of vstack\n",
    "tt.column_stack(tensors='List or tuple of tensors') # ->Tensor # Equivalent to torch.hstack(tensors), \n",
    "# except each zero or one dimensional tensor t in tensors is first reshaped into a (t.numel(), 1) column \n",
    "# before being stacked horizontally.\n",
    "\n",
    "tt.gather(input, dim='int', index='LongTensor', sparse_grad=False) # ->Tensor # Gathers values along an axis specified by dim. (is NOT a view)\n",
    "# input and index must have the same number of dimensions. \n",
    "# It is also required that index.size(d) <= input.size(d) for all dimensions d != dim. \n",
    "# out will have the same shape as index. Note that input and index do not broadcast against each other.\n",
    "# sparse_grad (bool, optional) – If True, gradient w.r.t. input will be a sparse tensor.\n",
    "\n",
    "tt.index_select(input, dim='int', index='(IntTensor or LongTensor) – the 1-D tensor containing the indices to index') # -> Tensor, NOT a view\n",
    "# The returned tensor does not use the same storage as the original tensor.\n",
    "#  If out has a different shape than expected, we silently change it to the correct shape, reallocating the underlying storage if necessary.\n",
    "tt.masked_select() # is similar function\n",
    "\n",
    "tt.movedim(input, \n",
    "            source='(int or tuple of ints) – Original positions of the dims to move. These must be unique.', \n",
    "            destination='(int or tuple of ints) – Destination positions for each of the original dims. These must also be unique.') \n",
    "# returns Tensor (View). Moves the dimension(s) of input at the position(s) in source to the position(s) in destination.\n",
    "# dimensions of input that are not explicitly moved remain in their original order and appear at the positions not specified in destination.\n",
    "tt.moveaxis() # alias of movedim\n",
    "\n",
    "# a similar function to 'movedim' is 'permute'\n",
    "tt.permute(input, dims='(tuple of python:int) – The desired ordering of dimensions') #<--- is a view\n",
    "tt.permute_copy(input, dims='(tuple of python:int) – The desired ordering of dimensions') #<--- is NOT a view\n",
    "\n",
    "\n",
    "tt.reshape() # this may or may not return a view\n",
    "\n",
    "\n",
    "# removing dims \n",
    "tt.narrow(), tt.squeeze(), tt.unsqueeze() #<--- is a view\n",
    "tt.narrow_copy(), tt.squeeze_copy(), tt.unsqueeze_copy() #<--- is NOT a view\n",
    "\n",
    "\n",
    "tt.transpose(input, dim0='int', dim1='int'), tt.transpose_copy() # Tensor\n",
    "# Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.\n",
    "tt.t(), tt.t_copy() # shot for teanspose - Expects input to be (<=2-D) tensor and transposes dimensions 0 and 1.\n",
    "tt.swapaxes(), tt.swapdims() # alias for transpose\n",
    "\n",
    "tt.tile() # repeating (tiling)\n",
    "tt.unbind(input, dim=0) # seq, splits but is NOT a view\n",
    "\n",
    "\n",
    "# selction\n",
    "tt.take(input, index='(LongTensor) – the indices into tensor') # Tensor\n",
    "# Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor. \n",
    "# The result takes the same shape as the indices.\n",
    "tt.take_along_dim(input, indices=' (tensor) – the indices into input. Must have long dtype.', dim='int') # Tensor\n",
    "# Selects values from input at the 1-dimensional indices from indices along the given dim.\n",
    "# Functions that return indices along a dimension, like torch.argmax() and torch.argsort(), \n",
    "# are designed to work with this function. See the examples below.\n",
    "\"\"\"\n",
    ">>> t = torch.tensor([[10, 30, 20], [60, 40, 50]])\n",
    ">>> max_idx = torch.argmax(t)\n",
    ">>> torch.take_along_dim(t, max_idx)\n",
    "tensor([60])\n",
    ">>> sorted_idx = torch.argsort(t, dim=1)\n",
    ">>> torch.take_along_dim(t, sorted_idx, dim=1)\n",
    "tensor([[10, 20, 30],\n",
    "        [40, 50, 60]])\n",
    "        \n",
    "\"\"\"\n",
    "\n",
    "# conditionals\n",
    "tt.nonzero(input='Tensor', as_tuple=False) # returns indices of non-zero positions\n",
    "tt.where(\n",
    "    condition='(BoolTensor)', \n",
    "    x='(Tensor or Scalar) – value (if x is a scalar) or values selected at indices where condition is True', \n",
    "    y='(Tensor or Scalar) – value (if y is a scalar) or values selected at indices where condition is False'\n",
    "    ) # Tensor - when only condition is supplied : torch.where(condition) → tuple of LongTensor (indices)\n",
    "\"\"\"\n",
    ">>> x = torch.randn(3, 2)\n",
    ">>> y = torch.ones(3, 2)\n",
    ">>> x\n",
    "tensor([[-0.4620,  0.3139],\n",
    "        [ 0.3898, -0.7197],\n",
    "        [ 0.0478, -0.1657]])\n",
    ">>> torch.where(x > 0, x, y)\n",
    "tensor([[ 1.0000,  0.3139],\n",
    "        [ 0.3898,  1.0000],\n",
    "        [ 0.0478,  1.0000]])\n",
    ">>> x = torch.randn(2, 2, dtype=torch.double)\n",
    ">>> x\n",
    "tensor([[ 1.0779,  0.0383],\n",
    "        [-0.8785, -1.1089]], dtype=torch.float64)\n",
    ">>> torch.where(x > 0, x, 0.)\n",
    "tensor([[1.0779, 0.0383],\n",
    "        [0.0000, 0.0000]], dtype=torch.float64)\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Operations\n",
    "\n",
    "see https://pytorch.org/docs/stable/torch.html#math-operations\n",
    "\n",
    "Types of Math Ops\n",
    "\n",
    "* https://pytorch.org/docs/stable/torch.html#pointwise-ops\n",
    "* https://pytorch.org/docs/stable/torch.html#reduction-ops\n",
    "* https://pytorch.org/docs/stable/torch.html#comparison-ops\n",
    "* https://pytorch.org/docs/stable/torch.html#spectral-ops\n",
    "* https://pytorch.org/docs/stable/torch.html#other-operations\n",
    "* https://pytorch.org/docs/stable/torch.html#blas-and-lapack-operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Type checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tt.zeros((2,3), dtype=tt.float32)\n",
    "tt.is_tensor(t), \\\n",
    "tt.is_floating_point(t), \\\n",
    "tt.is_nonzero(t[0,1]), \\\n",
    "tt.numel(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tt.get_default_dtype())\n",
    "\n",
    "# sets for current python session - restarting will reset \n",
    "# Supports torch.float32 and torch.float64 as inputs. \n",
    "# Other dtypes may be accepted without complaint but are not supported and are unlikely to work as expected\n",
    "tt.set_default_dtype(d=tt.float64) \n",
    "# tt.set_default_tensor_type(t=??) #<-- optinally use this\n",
    "\n",
    "print(tt.get_default_dtype())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared memory\n",
    "\n",
    "if array or tensors share memory - changing values will reflect accross all views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tt.arange(10)\n",
    "a1 = a.reshape(5,2)\n",
    "a2 = a[2:5]\n",
    "a, a1, a2, known.COMMON_TORCH.shares_memory(a1,a2)\n",
    "\n",
    "# similar for numpy\n",
    "#a = np.arange(10)\n",
    "#a1 = a.reshape(5,2)\n",
    "#a2 = a[2:5]\n",
    "#a, a1, a2, known.COMMON_NUMPY.shares_memory(a1,a2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing to output (verbose)\n",
    "\n",
    "use set_printoptions()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* precision – Number of digits of precision for floating point output (default = 4).\n",
    "\n",
    "* threshold – Total number of array elements which trigger summarization rather than full repr (default = 1000).\n",
    "\n",
    "* edgeitems – Number of array items in summary at beginning and end of each dimension (default = 3).\n",
    "\n",
    "* linewidth – The number of characters per line for the purpose of inserting line breaks (default = 80). Thresholded matrices will ignore this parameter.\n",
    "\n",
    "* profile – Sane defaults for pretty printing. Can override with any of the above options. (any one of default, short, full)\n",
    "\n",
    "* sci_mode – Enable (True) or disable (False) scientific notation. If None (default) is specified, the value is defined by torch._tensor_str._Formatter. This value is automatically chosen by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exactly same for numpy and torch\n",
    "#np.set_printoptions()\n",
    "tt.set_printoptions()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvenv310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fbec06f5f2f2aeb073e2e72ecfe9812985a9325e27355e80436989f5627ccd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
