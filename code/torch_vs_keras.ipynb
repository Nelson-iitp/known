{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version='3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]'\n",
      "np.__version__='1.22.2'\n",
      "tt.__version__='1.10.1+cu102'\n",
      "known.__version__='0.0.1'\n"
     ]
    }
   ],
   "source": [
    "# inbuilt \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# most common\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.functional as ff\n",
    "import torch.distributions as dd\n",
    "import torch.utils.data as ud\n",
    "\n",
    "# custom\n",
    "import known\n",
    "import known.ktorch as kt\n",
    "\n",
    "import known.ktorch.rnns.rnn_0 as rnn_0\n",
    "import known.ktorch.rnns.rnn_1 as rnn_1\n",
    "import known.ktorch.rnns.rnn_2 as rnn_2\n",
    "print(f'{sys.version=}\\n{np.__version__=}\\n{tt.__version__=}\\n{known.__version__=}')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 2)\n"
     ]
    }
   ],
   "source": [
    "input_size = 2\n",
    "seq_len = 4\n",
    "hidden_size = 3\n",
    "batch_size=1\n",
    "\n",
    "rng = np.random.default_rng(10)\n",
    "\n",
    "xx = rng.uniform(size=(batch_size, seq_len, input_size)).astype(np.float32)\n",
    "print(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 3), dtype=float32, numpy=\n",
       "array([[[-0.13218383, -0.11781129, -0.20121543],\n",
       "        [-0.18715054, -0.17592502, -0.29832956],\n",
       "        [-0.17149174, -0.15530027, -0.31345797],\n",
       "        [-0.19957122, -0.01634341, -0.511578  ]]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gru_keras = layers.GRU(hidden_size, return_sequences=True)\n",
    "out_gru_keras = gru_keras(xx)\n",
    "out_gru_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gru_keras_weights)=3\n"
     ]
    }
   ],
   "source": [
    "gru_keras_weights = gru_keras.get_weights()\n",
    "print(f'{len(gru_keras_weights)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 9) float32 [[ 0.24508941  0.5015604   0.13833356 -0.06305367 -0.64629054 -0.10404563\n",
      "  -0.33334228 -0.505028   -0.3268228 ]\n",
      " [ 0.54777604  0.32911712 -0.08986628 -0.22636646  0.60320705  0.32333213\n",
      "  -0.05923879  0.7194287  -0.69014966]]\n",
      "(3, 9) float32 [[-0.12936139 -0.316025    0.49045676  0.168047   -0.13731022  0.08267243\n",
      "  -0.21405011  0.427722    0.6001281 ]\n",
      " [-0.23423842 -0.10378698 -0.20747174  0.63924444  0.4949848   0.1764111\n",
      "  -0.02985656 -0.38566563  0.23858431]\n",
      " [ 0.20267263 -0.37664112 -0.10306689  0.34862775 -0.5382743  -0.5365092\n",
      "  -0.05048047 -0.32365122 -0.00462342]]\n",
      "(2, 9) float32 [[0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "for w in gru_keras_weights:\n",
    "    print(w.shape, w.dtype, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0, torch.Size([9, 2])\n",
      "weight_hh_l0, torch.Size([9, 3])\n",
      "bias_ih_l0, torch.Size([9])\n",
      "bias_hh_l0, torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "gru_torch = nn.GRU(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    bias=True,\n",
    "    batch_first=True,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    bidirectional=False,\n",
    "    dtype=tt.float32\n",
    ")\n",
    "sd_gru_torch = gru_torch.state_dict()\n",
    "for k,v in sd_gru_torch.items():\n",
    "    print(f'{k}, {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tt.no_grad():\n",
    "    gru_torch.get_parameter('weight_ih_l0').copy_(tt.tensor(gru_keras_weights[0].T))\n",
    "    gru_torch.get_parameter('weight_hh_l0').copy_(tt.tensor(gru_keras_weights[1].T))\n",
    "    gru_torch.get_parameter('bias_ih_l0').copy_(tt.tensor(gru_keras_weights[2].T[:,0]))\n",
    "    gru_torch.get_parameter('bias_hh_l0').copy_(tt.tensor(gru_keras_weights[2].T[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 2]) Parameter containing:\n",
      "tensor([[ 0.2451,  0.5478],\n",
      "        [ 0.5016,  0.3291],\n",
      "        [ 0.1383, -0.0899],\n",
      "        [-0.0631, -0.2264],\n",
      "        [-0.6463,  0.6032],\n",
      "        [-0.1040,  0.3233],\n",
      "        [-0.3333, -0.0592],\n",
      "        [-0.5050,  0.7194],\n",
      "        [-0.3268, -0.6901]], requires_grad=True)\n",
      "torch.Size([9, 3]) Parameter containing:\n",
      "tensor([[-0.1294, -0.2342,  0.2027],\n",
      "        [-0.3160, -0.1038, -0.3766],\n",
      "        [ 0.4905, -0.2075, -0.1031],\n",
      "        [ 0.1680,  0.6392,  0.3486],\n",
      "        [-0.1373,  0.4950, -0.5383],\n",
      "        [ 0.0827,  0.1764, -0.5365],\n",
      "        [-0.2141, -0.0299, -0.0505],\n",
      "        [ 0.4277, -0.3857, -0.3237],\n",
      "        [ 0.6001,  0.2386, -0.0046]], requires_grad=True)\n",
      "torch.Size([9]) Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "torch.Size([9]) Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    for p in gru_torch.parameters():\n",
    "        print(p.shape, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3]) tensor([[[-0.1683, -0.1996, -0.2168],\n",
      "         [-0.2151, -0.2336, -0.3181],\n",
      "         [-0.1707, -0.1600, -0.3287],\n",
      "         [-0.2118,  0.0547, -0.4854]]])\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    out_gru_torch, _ = gru_torch(tt.tensor(xx))\n",
    "print (out_gru_torch.shape, out_gru_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.0360751 , -0.08179066, -0.01554832],\n",
       "        [-0.02790597, -0.05766286, -0.01975289],\n",
       "        [ 0.0007631 , -0.00474924, -0.01525414],\n",
       "        [-0.01224101,  0.07103702,  0.026187  ]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_gru_torch.numpy() - out_gru_keras.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36896732"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out_gru_torch.numpy() - out_gru_keras.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_custom = rnn_0.GRU(\n",
    "    input_bias=True,\n",
    "    hidden_bias=True,\n",
    "    actF=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=(hidden_size,),       # hidden features at each layer\n",
    "    dropout=0.0,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=True,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    stack_output=True, # if true, stack output from all timesteps, else returns a list of outputs\n",
    "    dtype=tt.float32,\n",
    "    device=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_custom.copy_torch(gru_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[ 0.2451,  0.5478],\n",
      "        [ 0.5016,  0.3291],\n",
      "        [ 0.1383, -0.0899]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[-0.1294, -0.2342,  0.2027],\n",
      "        [-0.3160, -0.1038, -0.3766],\n",
      "        [ 0.4905, -0.2075, -0.1031]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[-0.0631, -0.2264],\n",
      "        [-0.6463,  0.6032],\n",
      "        [-0.1040,  0.3233]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[ 0.1680,  0.6392,  0.3486],\n",
      "        [-0.1373,  0.4950, -0.5383],\n",
      "        [ 0.0827,  0.1764, -0.5365]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[-0.3333, -0.0592],\n",
      "        [-0.5050,  0.7194],\n",
      "        [-0.3268, -0.6901]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[-0.2141, -0.0299, -0.0505],\n",
      "        [ 0.4277, -0.3857, -0.3237],\n",
      "        [ 0.6001,  0.2386, -0.0046]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    for p in gru_custom.parameters():\n",
    "        print(p.shape, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3]) tensor([[[-0.1683, -0.1996, -0.2168],\n",
      "         [-0.2151, -0.2336, -0.3181],\n",
      "         [-0.1707, -0.1600, -0.3287],\n",
      "         [-0.2118,  0.0547, -0.4854]]])\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    out_gru_custom, _ = gru_custom(tt.tensor(xx))\n",
    "print (out_gru_custom.shape, out_gru_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 1.4901161e-08, -1.4901161e-08,  0.0000000e+00],\n",
       "        [ 0.0000000e+00, -1.4901161e-08,  0.0000000e+00],\n",
       "        [ 0.0000000e+00, -1.4901161e-08,  0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_gru_custom.numpy() - out_gru_torch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.9604645e-08"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out_gru_custom.numpy() - out_gru_torch.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.0360751 , -0.08179066, -0.01554832],\n",
       "        [-0.02790596, -0.05766287, -0.01975289],\n",
       "        [ 0.0007631 , -0.00474925, -0.01525414],\n",
       "        [-0.01224101,  0.071037  ,  0.026187  ]]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_gru_custom.numpy() - out_gru_keras.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3689673"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out_gru_custom.numpy() - out_gru_keras.numpy()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4, 3), dtype=float32, numpy=\n",
       "array([[[0.07615212, 0.03750532, 0.03732687],\n",
       "        [0.12489272, 0.06556307, 0.04804401],\n",
       "        [0.14298427, 0.074992  , 0.04078937],\n",
       "        [0.22945048, 0.05844793, 0.03792481]]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_keras = layers.LSTM(hidden_size, return_sequences=True)\n",
    "out_lstm_keras = lstm_keras(xx)\n",
    "out_lstm_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lstm_keras_weights)=3\n"
     ]
    }
   ],
   "source": [
    "lstm_keras_weights = lstm_keras.get_weights()\n",
    "print(f'{len(lstm_keras_weights)=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 12) float32 [[-0.16593987 -0.562787    0.51564646  0.13148141 -0.03364134 -0.62979895\n",
      "   0.25195098  0.2638734   0.15455168  0.25584412  0.04808438 -0.4428633 ]\n",
      " [ 0.07767743 -0.19603553  0.43247926 -0.46720794  0.01474583  0.17917931\n",
      "   0.24092597 -0.18939957  0.04401672  0.43179798 -0.2470138  -0.42046884]]\n",
      "(3, 12) float32 [[-0.3884369   0.09312984 -0.35791096 -0.18676479  0.29619458  0.34487045\n",
      "   0.5095191   0.23359406 -0.24399294 -0.26757216  0.14015505 -0.0764764 ]\n",
      " [ 0.37449586  0.07638407 -0.23299094  0.26163605 -0.03129346  0.12542845\n",
      "   0.13972591 -0.04758845 -0.5246375   0.08506239 -0.41515207  0.4876979 ]\n",
      " [ 0.05110543  0.6813131  -0.17572173  0.39505234  0.34311208 -0.24711327\n",
      "  -0.15951802 -0.19148712  0.0113897  -0.13146505  0.29318908 -0.04448877]]\n",
      "(12,) float32 [0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for w in lstm_keras_weights:\n",
    "    print(w.shape, w.dtype, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_ih_l0, torch.Size([12, 2])\n",
      "weight_hh_l0, torch.Size([12, 3])\n",
      "bias_ih_l0, torch.Size([12])\n",
      "bias_hh_l0, torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "lstm_torch = nn.LSTM(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    bias=True,\n",
    "    batch_first=True,\n",
    "    num_layers=1,\n",
    "    dropout=0.0,\n",
    "    bidirectional=False,\n",
    "    dtype=tt.float32\n",
    ")\n",
    "sd_lstm_torch = lstm_torch.state_dict()\n",
    "for k,v in sd_lstm_torch.items():\n",
    "    print(f'{k}, {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tt.no_grad():\n",
    "    lstm_torch.get_parameter('weight_ih_l0').copy_(tt.tensor(lstm_keras_weights[0].T))\n",
    "    lstm_torch.get_parameter('weight_hh_l0').copy_(tt.tensor(lstm_keras_weights[1].T))\n",
    "    lstm_torch.get_parameter('bias_ih_l0').copy_(tt.tensor(lstm_keras_weights[2]))\n",
    "    lstm_torch.get_parameter('bias_hh_l0').copy_(tt.zeros(lstm_keras_weights[2].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 2]) Parameter containing:\n",
      "tensor([[-0.1659,  0.0777],\n",
      "        [-0.5628, -0.1960],\n",
      "        [ 0.5156,  0.4325],\n",
      "        [ 0.1315, -0.4672],\n",
      "        [-0.0336,  0.0147],\n",
      "        [-0.6298,  0.1792],\n",
      "        [ 0.2520,  0.2409],\n",
      "        [ 0.2639, -0.1894],\n",
      "        [ 0.1546,  0.0440],\n",
      "        [ 0.2558,  0.4318],\n",
      "        [ 0.0481, -0.2470],\n",
      "        [-0.4429, -0.4205]], requires_grad=True)\n",
      "torch.Size([12, 3]) Parameter containing:\n",
      "tensor([[-0.3884,  0.3745,  0.0511],\n",
      "        [ 0.0931,  0.0764,  0.6813],\n",
      "        [-0.3579, -0.2330, -0.1757],\n",
      "        [-0.1868,  0.2616,  0.3951],\n",
      "        [ 0.2962, -0.0313,  0.3431],\n",
      "        [ 0.3449,  0.1254, -0.2471],\n",
      "        [ 0.5095,  0.1397, -0.1595],\n",
      "        [ 0.2336, -0.0476, -0.1915],\n",
      "        [-0.2440, -0.5246,  0.0114],\n",
      "        [-0.2676,  0.0851, -0.1315],\n",
      "        [ 0.1402, -0.4152,  0.2932],\n",
      "        [-0.0765,  0.4877, -0.0445]], requires_grad=True)\n",
      "torch.Size([12]) Parameter containing:\n",
      "tensor([0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "torch.Size([12]) Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    for p in lstm_torch.parameters():\n",
    "        print(p.shape, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3]) tensor([[[0.0762, 0.0375, 0.0373],\n",
      "         [0.1249, 0.0656, 0.0480],\n",
      "         [0.1430, 0.0750, 0.0408],\n",
      "         [0.2295, 0.0584, 0.0379]]])\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    out_lstm_torch, _ = lstm_torch(tt.tensor(xx))\n",
    "print (out_lstm_torch.shape, out_lstm_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.4505806e-09, 1.1175871e-08, 3.7252903e-09],\n",
       "        [2.2351742e-08, 1.4901161e-08, 0.0000000e+00],\n",
       "        [1.4901161e-08, 2.2351742e-08, 7.4505806e-09],\n",
       "        [2.9802322e-08, 2.6077032e-08, 0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_lstm_torch.numpy() - out_lstm_keras.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6018748e-07"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out_lstm_torch.numpy() - out_lstm_keras.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_custom = rnn_0.LSTM(\n",
    "    input_bias=True,\n",
    "    hidden_bias=True,\n",
    "    actF=tt.tanh, actC=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=(hidden_size,),       # hidden features at each layer\n",
    "    dropout=0.0,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=True,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    stack_output=True, # if true, stack output from all timesteps, else returns a list of outputs\n",
    "    dtype=tt.float32,\n",
    "    device=None,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_custom.copy_torch(lstm_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[-0.1659,  0.0777],\n",
      "        [-0.5628, -0.1960],\n",
      "        [ 0.5156,  0.4325]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[-0.3884,  0.3745,  0.0511],\n",
      "        [ 0.0931,  0.0764,  0.6813],\n",
      "        [-0.3579, -0.2330, -0.1757]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[ 0.1315, -0.4672],\n",
      "        [-0.0336,  0.0147],\n",
      "        [-0.6298,  0.1792]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([1., 1., 1.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[-0.1868,  0.2616,  0.3951],\n",
      "        [ 0.2962, -0.0313,  0.3431],\n",
      "        [ 0.3449,  0.1254, -0.2471]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[ 0.2520,  0.2409],\n",
      "        [ 0.2639, -0.1894],\n",
      "        [ 0.1546,  0.0440]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[ 0.5095,  0.1397, -0.1595],\n",
      "        [ 0.2336, -0.0476, -0.1915],\n",
      "        [-0.2440, -0.5246,  0.0114]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 2]) Parameter containing:\n",
      "tensor([[ 0.2558,  0.4318],\n",
      "        [ 0.0481, -0.2470],\n",
      "        [-0.4429, -0.4205]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n",
      "torch.Size([3, 3]) Parameter containing:\n",
      "tensor([[-0.2676,  0.0851, -0.1315],\n",
      "        [ 0.1402, -0.4152,  0.2932],\n",
      "        [-0.0765,  0.4877, -0.0445]], requires_grad=True)\n",
      "torch.Size([3]) Parameter containing:\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    for p in lstm_custom.parameters():\n",
    "        print(p.shape, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 3]) tensor([[[0.0762, 0.0375, 0.0373],\n",
      "         [0.1249, 0.0656, 0.0480],\n",
      "         [0.1430, 0.0750, 0.0408],\n",
      "         [0.2295, 0.0584, 0.0379]]])\n"
     ]
    }
   ],
   "source": [
    "with tt.no_grad():\n",
    "    out_lstm_custom, _ = lstm_custom(tt.tensor(xx))\n",
    "print (out_lstm_custom.shape, out_lstm_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_lstm_custom.numpy() - out_lstm_torch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out_lstm_custom.numpy() - out_lstm_torch.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.4505806e-09, 1.1175871e-08, 3.7252903e-09],\n",
       "        [2.2351742e-08, 1.4901161e-08, 0.0000000e+00],\n",
       "        [1.4901161e-08, 2.2351742e-08, 7.4505806e-09],\n",
       "        [2.9802322e-08, 2.6077032e-08, 0.0000000e+00]]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_lstm_custom.numpy() - out_lstm_keras.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6018748e-07"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(out_lstm_custom.numpy() - out_lstm_keras.numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "570feb405e2e27c949193ac68f46852414290d515b0ba6e5d90d076ed2284471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
