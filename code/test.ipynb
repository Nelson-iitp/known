{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inbuilt \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# most common\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.optim as oo\n",
    "import torch.functional as ff\n",
    "import torch.distributions as dd\n",
    "import torch.utils.data as ud\n",
    "\n",
    "# custom\n",
    "import known\n",
    "import known.ktorch as kt\n",
    "\n",
    "print(f'{sys.version=}\\n{np.__version__=}\\n{tt.__version__=}\\n{known.__version__=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(rng, n, d):\n",
    "    x=np.linspace(0, 10*np.pi, n)\n",
    "    if d==0:\n",
    "        y = 10*np.sin(x)\n",
    "    elif d==1:\n",
    "        y = -5*np.cos(x)\n",
    "    elif d==2:\n",
    "        y = 7*np.sin(x) + -9*np.cos(x)\n",
    "    else:\n",
    "        print('invalid dim')\n",
    "    return y\n",
    "\n",
    "kt.SeqDataset.generate(\n",
    "    genF=gen,\n",
    "    genS=1000,\n",
    "    colS=['a', 'b', 'c'], normalize=False, file_name='train.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqlen = 24\n",
    "cols = ('PRICE',)\n",
    "input_size = len(cols)\n",
    "ds = kt.SeqDataset.from_csv('PJDS.csv', cols=cols, seqlen=seqlen, reverse=True, normalize=False, squeeze_label=True, dtype=tt.float32)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnMlp(nn.Module):\n",
    "    def __init__(self, rnn_class) -> None:\n",
    "        super().__init__()\n",
    "        self.rnn_class = rnn_class\n",
    "        rnnargs = dict(\n",
    "            input_size=input_size, hidden_sizes=(8, 8, 8), actF=tt.tanh, batch_first=True, dtype=tt.float32\n",
    "        )\n",
    "        if rnn_class is kt.ELMAN or rnn_class is kt.GRU or rnn_class is kt.MGU: \n",
    "            self.rnn = rnn_class(True, False, **rnnargs)\n",
    "        elif rnn_class is kt.JANET:\n",
    "            rnnargs['beta']=0.0\n",
    "            self.rnn = rnn_class(True, False, **rnnargs)\n",
    "        elif rnn_class is kt.LSTM:\n",
    "            rnnargs['actC']=tt.tanh\n",
    "            self.rnn = rnn_class(True, False, **rnnargs)\n",
    "        elif rnn_class is nn.RNN or rnn_class is nn.GRU or rnn_class is nn.LSTM:\n",
    "            self.rnn = rnn_class(input_size=input_size, hidden_size=8, num_layers=3, batch_first=True)\n",
    "        else:\n",
    "            print('Invalid_RNN_Class')\n",
    "            \n",
    "        \n",
    "        self.fc = nn.Sequential( nn.Flatten(), nn.Linear(8, input_size))\n",
    "        #self.fc = nn.Flatten()\n",
    "\n",
    "    def forward(self, X):\n",
    "        x, *_ = self.rnn(X)\n",
    "        #y = self.fc(x[-1])\n",
    "        return self.fc(x[:, -1, :])\n",
    "\n",
    "rnms = [    RnnMlp(kt.ELMAN),   RnnMlp(kt.GRU),     RnnMlp(kt.JANET),   RnnMlp(kt.MGU),     RnnMlp(kt.LSTM), \n",
    "            RnnMlp(nn.RNN),     RnnMlp(nn.GRU),     RnnMlp(nn.LSTM)     ]\n",
    "rnmc = [    'tab:blue',         'tab:red',          'tab:green',        'tab:brown',       'tab:olive',\n",
    "            'tab:pink',         'tab:orange',        'tab:grey'          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ds.dataloader(batch_size=32)\n",
    "print(len(dl))\n",
    "dli = iter(dl)\n",
    "x,y = next(dli)\n",
    "with tt.no_grad():\n",
    "    h = rnms[0](x)\n",
    "x.shape, y.shape, h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history={}\n",
    "for rnm in rnms:\n",
    "    print(rnm.rnn_class)\n",
    "    history = kt.utils.train( rnm,\n",
    "        training_data=ds, \n",
    "        validation_data=ds, \n",
    "        testing_data=ds,\n",
    "        epochs=500, \n",
    "        batch_size=32, \n",
    "        shuffle=True, \n",
    "        validation_freq=5, \n",
    "        criterion_type=nn.MSELoss, \n",
    "        criterion_args={}, \n",
    "        optimizer_type=oo.Adam, \n",
    "        optimizer_args={'lr': 0.005, 'weight_decay': 0.0}, \n",
    "        lrs_type=oo.lr_scheduler.LinearLR, \n",
    "        lrs_args={'start_factor': 1.0, 'end_factor':0.7, 'total_iters': 2000},\n",
    "        record_batch_loss=False, \n",
    "        early_stop_train=None,#kt.QuantiyMonitor('TrainLoss', patience=50, delta=0.00001, verbose=False), \n",
    "        early_stop_val=None, #kt.QuantiyMonitor('ValLoss', patience=50, delta=0.00001, verbose=False), \n",
    "        checkpoint_freq=5, \n",
    "        save_path='sample.rnn',\n",
    "        save_state_only=True, \n",
    "        verbose=1, \n",
    "        plot=1\n",
    "    )\n",
    "    all_history[f'{rnm.rnn_class}'] = history\n",
    "    print('=================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_history={}\n",
    "for rnm in rnms:\n",
    "    print(rnm.rnn_class)\n",
    "    model=rnm\n",
    "    epochs = 50\n",
    "    batch_size=32\n",
    "    shuffle=True\n",
    "    validation_freq = int(epochs/10)\n",
    "    criterion=nn.MSELoss()\n",
    "    lr = 0.005\n",
    "    weight_decay = 0.0\n",
    "    optimizer=oo.Adam(rnm.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    lrs=oo.lr_scheduler.LinearLR(optimizer, start_factor= 1.0, end_factor=0.7, total_iters=epochs)\n",
    "\n",
    "    early_stop_train=kt.QuantiyMonitor('TrainLoss', patience=50, delta=0.00001)\n",
    "    early_stop_val=kt.QuantiyMonitor('ValLoss', patience=50, delta=0.00001)\n",
    "    checkpoint_freq=int(epochs/4)\n",
    "    save_path='sample.rnn'\n",
    "    loss_plot_start = int(epochs/50)\n",
    "\n",
    "    history = kt.utils.train_( \n",
    "        model=model, \n",
    "        training_data=ds, validation_data=ds, testing_data=ds,\n",
    "            epochs=epochs, batch_size=batch_size, shuffle=shuffle, validation_freq=validation_freq, \n",
    "            criterion=criterion, optimizer=optimizer, lrs=lrs,\n",
    "            record_batch_loss=False, early_stop_train=early_stop_train, early_stop_val=early_stop_val, checkpoint_freq=checkpoint_freq, \n",
    "            save_path=None, save_state_only=False, verbose=1, plot=1, loss_plot_start=loss_plot_start)\n",
    "\n",
    "    all_history[f'{rnm.rnn_class}'] = history\n",
    "    print('=================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "l = []\n",
    "for k,v in all_history.items():\n",
    "    ll, vl, tl = v['loss'][-1], v['val_loss'][-1], v['test_loss']\n",
    "    print(f'{k}:\\t{ll, vl, tl}')\n",
    "    y.append(v[1])\n",
    "    sl = k.split('.')\n",
    "    l.append(sl[1]+\".\"+sl[-1][:-2])\n",
    "\n",
    "x= range(len(all_history))\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.bar(x , y )\n",
    "plt.xticks(x, l)\n",
    "plt.ylabel('val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for rnm in rnms:\n",
    "    print(rnm.rnn_class)\n",
    "    rnm.eval()\n",
    "    with tt.no_grad():\n",
    "        for iv,(Xv,Yv) in enumerate(ds.dataloader(batch_size=len(ds)), 0):\n",
    "            Pv = rnm(Xv)\n",
    "            res.append(Pv)#print(Xv.shape, Yv.shape, Pv.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(input_size):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.title(f'{i}')\n",
    "    \n",
    "    plt.plot(Yv[:,i], color='black', label='Truth')\n",
    "    for r,rnm,c in zip(res,rnms,rnmc):\n",
    "        plt.plot(Pv[:,i], color=c, label=f'{rnm.rnn_class}', linestyle='dotted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    print('=================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "__venv310__",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fe6015140738806d41bf643a20b25ab509e1558f046cb4d7778c2b8bb5aa7b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
