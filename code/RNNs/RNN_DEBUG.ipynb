{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version='3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]'\n",
      "np.__version__='1.24.1'\n",
      "tt.__version__='1.13.1+cpu'\n",
      "known.__version__='0.0.1'\n"
     ]
    }
   ],
   "source": [
    "# inbuilt \n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "# most common\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pytorch\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.functional as ff\n",
    "import torch.distributions as dd\n",
    "import torch.utils.data as ud\n",
    "\n",
    "import random\n",
    "import time\n",
    "# custom\n",
    "import known\n",
    "import known.ktorch as kt\n",
    "print(f'{sys.version=}\\n{np.__version__=}\\n{tt.__version__=}\\n{known.__version__=}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual-Seed: 281703975047300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set seed\n",
    "tt.manual_seed(281703975047300) # manually sets a seed for random sampling creation ops\n",
    "print('Manual-Seed:', tt.initial_seed()) # current seed for default rng\n",
    "\n",
    "batch_size = 5 \n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "seq_len = 3\n",
    "\n",
    "dt=tt.float32\n",
    "batch_first=True\n",
    "dropout=0.0\n",
    "num_layers = 2\n",
    "\n",
    "num_samples=50\n",
    "num_loops=10\n",
    "\n",
    "xx = [tt.rand(size=(batch_size, seq_len, input_size), dtype=dt) for _ in range(num_samples)] \\\n",
    "            if batch_first else \\\n",
    "    [tt.rand(size=(seq_len, batch_size, input_size), dtype=dt) for _ in range(num_samples) ]\n",
    "len(xx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Built Cells"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_torch = nn.RNN(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    nonlinearity='tanh',\n",
    "    batch_first=batch_first,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    dtype=dt\n",
    ")\n",
    "rnn = kt.ELMAN(\n",
    "    input_bias=True,\n",
    "    hidden_bias=True,\n",
    "    actF=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=[hidden_size for _ in range(num_layers)],       # hidden features at each layer\n",
    "    dropout=dropout,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=batch_first,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    dtype=dt,\n",
    "    device=None,\n",
    "    stack_output=False\n",
    ")\n",
    "\n",
    "rnnc = kt.ELMANC(\n",
    "    has_bias=True,\n",
    "    actF=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=[hidden_size for _ in range(num_layers)],       # hidden features at each layer\n",
    "    dropout=dropout,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=batch_first,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    dtype=dt,\n",
    "    device=None,\n",
    "    stack_output=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_torch = nn.GRU(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    #nonlinearity='tanh',\n",
    "    batch_first=batch_first,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    dtype=dt\n",
    ")\n",
    "rnn = kt.GRU(\n",
    "    input_bias=True,\n",
    "    hidden_bias=True,\n",
    "    actF=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=[hidden_size for _ in range(num_layers)],       # hidden features at each layer\n",
    "    dropout=dropout,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=batch_first,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    dtype=dt,\n",
    "    device=None,\n",
    "    stack_output=False\n",
    ")\n",
    "\n",
    "rnnc = kt.GRUC(\n",
    "    has_bias=True,\n",
    "    actF=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=[hidden_size for _ in range(num_layers)],       # hidden features at each layer\n",
    "    dropout=dropout,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=batch_first,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    dtype=dt,\n",
    "    device=None,\n",
    "    stack_output=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_torch = nn.LSTM(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    #nonlinearity='tanh',\n",
    "    batch_first=batch_first,\n",
    "    num_layers=num_layers,\n",
    "    dropout=dropout,\n",
    "    dtype=dt\n",
    ")\n",
    "rnn = kt.LSTM(\n",
    "    input_bias=True,\n",
    "    hidden_bias=True,\n",
    "    actF=tt.tanh, actC=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=[hidden_size for _ in range(num_layers)],       # hidden features at each layer\n",
    "    dropout=dropout,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=batch_first,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    dtype=dt,\n",
    "    device=None,\n",
    "    stack_output=False\n",
    ")\n",
    "\n",
    "rnnc = kt.LSTMC(\n",
    "    has_bias=True,\n",
    "    actF=tt.tanh, actC=tt.tanh,\n",
    "    input_size=input_size,         # input features\n",
    "    hidden_sizes=[hidden_size for _ in range(num_layers)],       # hidden features at each layer\n",
    "    dropout=dropout,        # dropout after each layer, only if hidden_sizes > 1\n",
    "    batch_first=batch_first,  # if true, excepts input as (batch_size, seq_len, input_size) else (seq_len, batch_size, input_size)\n",
    "    dtype=dt,\n",
    "    device=None,\n",
    "    stack_output=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genralized RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnng = kt.GRNN(\n",
    "    core = kt.clone_model(rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: torch.Size([5, 4]), ([tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]), tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])],)\n",
      "normal: torch.Size([5, 4]), ([tensor([[-0.4444,  0.1310,  0.5923,  0.0797],\n",
      "        [-0.4517, -0.1712,  0.2867, -0.0010],\n",
      "        [-0.4296, -0.2081,  0.1454, -0.2569],\n",
      "        [-0.4565,  0.0579,  0.4627,  0.3336],\n",
      "        [-0.4214, -0.1956,  0.2875,  0.0041]], grad_fn=<TanhBackward0>), tensor([[-0.3891,  0.0936, -0.4259, -0.1638],\n",
      "        [-0.2377, -0.0969, -0.4606, -0.0076],\n",
      "        [-0.2157, -0.1953, -0.4494, -0.0659],\n",
      "        [-0.3049,  0.0689, -0.4375, -0.0146],\n",
      "        [-0.2235, -0.1103, -0.4574,  0.0120]], grad_fn=<TanhBackward0>)],)\n",
      "normal: torch.Size([5, 4]), ([tensor([[ 0.1123, -0.1162,  0.2428, -0.0371],\n",
      "        [-0.1452,  0.1335,  0.3507,  0.0909],\n",
      "        [-0.4597, -0.0328, -0.1335,  0.3348],\n",
      "        [-0.3657,  0.1386,  0.4358,  0.4527],\n",
      "        [-0.2571, -0.0826,  0.0110, -0.0165]], grad_fn=<TanhBackward0>), tensor([[-0.0903, -0.0486, -0.2840,  0.3200],\n",
      "        [-0.1696,  0.1309, -0.4705,  0.0492],\n",
      "        [-0.0516,  0.0280, -0.5526,  0.2384],\n",
      "        [-0.1955,  0.2772, -0.4690,  0.1771],\n",
      "        [-0.0397, -0.0268, -0.5232,  0.1224]], grad_fn=<TanhBackward0>)],)\n"
     ]
    }
   ],
   "source": [
    "x = xx[0]\n",
    "Y, H= rnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal: torch.Size([5, 4]), ([tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]]), tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])],)\n",
      "normal: torch.Size([5, 4]), ([tensor([[-0.4444,  0.1310,  0.5923,  0.0797],\n",
      "        [-0.4517, -0.1712,  0.2867, -0.0010],\n",
      "        [-0.4296, -0.2081,  0.1454, -0.2569],\n",
      "        [-0.4565,  0.0579,  0.4627,  0.3336],\n",
      "        [-0.4214, -0.1956,  0.2875,  0.0041]], grad_fn=<TanhBackward0>), tensor([[-0.3891,  0.0936, -0.4259, -0.1638],\n",
      "        [-0.2377, -0.0969, -0.4606, -0.0076],\n",
      "        [-0.2157, -0.1953, -0.4494, -0.0659],\n",
      "        [-0.3049,  0.0689, -0.4375, -0.0146],\n",
      "        [-0.2235, -0.1103, -0.4574,  0.0120]], grad_fn=<TanhBackward0>)],)\n",
      "normal: torch.Size([5, 4]), ([tensor([[ 0.1123, -0.1162,  0.2428, -0.0371],\n",
      "        [-0.1452,  0.1335,  0.3507,  0.0909],\n",
      "        [-0.4597, -0.0328, -0.1335,  0.3348],\n",
      "        [-0.3657,  0.1386,  0.4358,  0.4527],\n",
      "        [-0.2571, -0.0826,  0.0110, -0.0165]], grad_fn=<TanhBackward0>), tensor([[-0.0903, -0.0486, -0.2840,  0.3200],\n",
      "        [-0.1696,  0.1309, -0.4705,  0.0492],\n",
      "        [-0.0516,  0.0280, -0.5526,  0.2384],\n",
      "        [-0.1955,  0.2772, -0.4690,  0.1771],\n",
      "        [-0.0397, -0.0268, -0.5232,  0.1224]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[-0.4932,  0.0557,  0.4536, -0.2350],\n",
      "        [-0.0222,  0.0363,  0.4286, -0.2976],\n",
      "        [-0.4069,  0.0708,  0.5177,  0.4569],\n",
      "        [ 0.1567, -0.1397,  0.2721,  0.0797],\n",
      "        [-0.4357, -0.0502,  0.2961,  0.3112]], grad_fn=<TanhBackward0>), tensor([[-0.2168,  0.1401, -0.6269, -0.3304],\n",
      "        [-0.1091,  0.0437, -0.4176, -0.0665],\n",
      "        [-0.0263,  0.3054, -0.6384, -0.0089],\n",
      "        [ 0.1538, -0.0341, -0.3996,  0.1826],\n",
      "        [-0.0092,  0.1700, -0.6212,  0.0624]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[-0.2002,  0.0613, -0.4014,  0.1366],\n",
      "        [-0.3623, -0.0284, -0.2809, -0.0800],\n",
      "        [ 0.1055, -0.0234, -0.0439,  0.1921],\n",
      "        [-0.2683, -0.0712, -0.0050, -0.1176],\n",
      "        [-0.0318,  0.0774, -0.0275,  0.2455]], grad_fn=<TanhBackward0>), tensor([[ 0.0805, -0.1025, -0.2935,  0.3732],\n",
      "        [ 0.0192, -0.1376, -0.4479,  0.1045],\n",
      "        [ 0.2666, -0.0824, -0.3571,  0.2541],\n",
      "        [ 0.0947, -0.1249, -0.5782, -0.1320],\n",
      "        [ 0.2067, -0.0108, -0.4461,  0.1440]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[-0.2718,  0.1664,  0.3216,  0.2270],\n",
      "        [-0.2918,  0.1946,  0.0683,  0.2243],\n",
      "        [-0.1893, -0.0291,  0.2239, -0.0642],\n",
      "        [-0.2120,  0.0752, -0.1153,  0.0472],\n",
      "        [-0.0914, -0.0274,  0.1949,  0.0063]], grad_fn=<TanhBackward0>), tensor([[-0.0311,  0.0926, -0.6116, -0.2433],\n",
      "        [-0.0232,  0.0566, -0.5532, -0.0665],\n",
      "        [ 0.0671, -0.0827, -0.6019, -0.2292],\n",
      "        [ 0.0506, -0.0780, -0.4955,  0.0687],\n",
      "        [ 0.1033, -0.0762, -0.5422, -0.0917]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[ 0.0457, -0.0903, -0.1191,  0.0125],\n",
      "        [-0.0206, -0.0007,  0.0359,  0.1214],\n",
      "        [-0.1455, -0.0225, -0.1951, -0.0632],\n",
      "        [-0.1880,  0.0823,  0.0821,  0.1150],\n",
      "        [-0.1622, -0.0312, -0.0972, -0.0719]], grad_fn=<TanhBackward0>), tensor([[ 0.1400, -0.1647, -0.3409,  0.3018],\n",
      "        [ 0.1005, -0.0616, -0.4220,  0.1745],\n",
      "        [ 0.0797, -0.1573, -0.4438,  0.1603],\n",
      "        [ 0.0388, -0.0037, -0.5331, -0.0179],\n",
      "        [ 0.0821, -0.1374, -0.4921,  0.0603]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[-0.3377,  0.0681,  0.1551,  0.0116],\n",
      "        [-0.2127,  0.0087,  0.1011,  0.0108],\n",
      "        [-0.3027,  0.1244,  0.0916,  0.1034],\n",
      "        [-0.1173,  0.0067,  0.0052,  0.0598],\n",
      "        [-0.2671,  0.0925,  0.0155,  0.0680]], grad_fn=<TanhBackward0>), tensor([[-0.0025, -0.0054, -0.6357, -0.2551],\n",
      "        [ 0.0579, -0.0485, -0.5669, -0.1043],\n",
      "        [-0.0015,  0.0241, -0.5930, -0.1346],\n",
      "        [ 0.0890, -0.0684, -0.4802,  0.0804],\n",
      "        [ 0.0229, -0.0184, -0.5601, -0.0606]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[-0.0772,  0.0071, -0.1646,  0.0592],\n",
      "        [-0.1490,  0.0161, -0.0842,  0.0302],\n",
      "        [-0.0659,  0.0133, -0.0530,  0.0975],\n",
      "        [-0.1992,  0.0357,  0.0478,  0.0426],\n",
      "        [-0.1205,  0.0420, -0.0111,  0.1022]], grad_fn=<TanhBackward0>), tensor([[ 0.0969, -0.1170, -0.3923,  0.2474],\n",
      "        [ 0.0812, -0.0938, -0.4728,  0.1049],\n",
      "        [ 0.1003, -0.0777, -0.4225,  0.1882],\n",
      "        [ 0.0596, -0.0464, -0.5411, -0.0400],\n",
      "        [ 0.0778, -0.0503, -0.4689,  0.1087]], grad_fn=<TanhBackward0>)],)\n",
      "future: torch.Size([5, 4]), ([tensor([[-0.2704,  0.0892,  0.1716,  0.0887],\n",
      "        [-0.2225,  0.0724,  0.0756,  0.0795],\n",
      "        [-0.2240,  0.0453,  0.1287,  0.0523],\n",
      "        [-0.1526,  0.0280, -0.0230,  0.0520],\n",
      "        [-0.1825,  0.0353,  0.0844,  0.0611]], grad_fn=<TanhBackward0>), tensor([[ 0.0125,  0.0198, -0.6018, -0.1765],\n",
      "        [ 0.0389, -0.0149, -0.5552, -0.0648],\n",
      "        [ 0.0438, -0.0196, -0.5746, -0.1202],\n",
      "        [ 0.0744, -0.0687, -0.4919,  0.0640],\n",
      "        [ 0.0612, -0.0344, -0.5405, -0.0437]], grad_fn=<TanhBackward0>)],)\n"
     ]
    }
   ],
   "source": [
    "Y, H= rnn(x, future=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known.about(x)\n",
    "known.about(Y)\n",
    "known.about(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known.about(Y[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compar time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_torch = []\n",
    "\n",
    "for _ in range(num_loops):\n",
    "    start_at = time.time()\n",
    "    for x in xx: _ = rnn_torch(x)\n",
    "    end_at = time.time()\n",
    "    eta_torch.append(end_at-start_at)\n",
    "    \n",
    "print(np.mean(eta_torch), np.sum(eta_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_inherit = []\n",
    "\n",
    "for _ in range(num_loops):\n",
    "    start_at = time.time()\n",
    "    for x in xx: _ = rnn(x)\n",
    "    end_at = time.time()\n",
    "    eta_inherit.append(end_at-start_at)\n",
    "    \n",
    "print(np.mean(eta_inherit), np.sum(eta_inherit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_gen = []\n",
    "\n",
    "for _ in range(num_loops):\n",
    "    start_at = time.time()\n",
    "    for x in xx: _ = rnng(x)\n",
    "    end_at = time.time()\n",
    "    eta_gen.append(end_at-start_at)\n",
    "    \n",
    "print(np.mean(eta_gen), np.sum(eta_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_comb = []\n",
    "\n",
    "for _ in range(num_loops):\n",
    "    start_at = time.time()\n",
    "    for x in xx: _ = rnnc(x)\n",
    "    end_at = time.time()\n",
    "    eta_comb.append(end_at-start_at)\n",
    "    \n",
    "print(np.mean(eta_comb), np.sum(eta_comb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,6))\n",
    "\n",
    "xr = np.arange(num_loops)\n",
    "plt.scatter(xr, eta_torch, label='eta_torch', color='blue' )\n",
    "plt.scatter(xr, eta_inherit, label='eta_inherit' , color='green')\n",
    "plt.scatter(xr, eta_gen, label='eta_gen' , color='red')\n",
    "plt.scatter(xr, eta_comb, label='eta_comb' , color='brown')\n",
    "\n",
    "plt.plot(xr, eta_torch , color='blue')\n",
    "plt.plot(xr, eta_inherit , color='green')\n",
    "plt.plot(xr, eta_gen , color='red')\n",
    "plt.plot(xr, eta_comb , color='brown')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.bar([1], [np.sum(eta_torch)], color='blue')\n",
    "plt.bar([2], [np.sum(eta_inherit)], color='green')\n",
    "plt.bar([3], [np.sum(eta_gen)], color='red')\n",
    "plt.bar([4], [np.sum(eta_comb)], color='brown')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "__venv310__",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fe6015140738806d41bf643a20b25ab509e1558f046cb4d7778c2b8bb5aa7b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
